{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../code-python3\")\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from linear_algebra import dot, vector_add\n",
    "from stats import median, standard_deviation\n",
    "from probability import normal_cdf\n",
    "from gradient_descent import minimize_stochastic\n",
    "from simple_linear_regression import total_sum_of_squares\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x_i, beta):\n",
    "    return dot(x_i, beta)\n",
    "\n",
    "def error(x_i, y_i, beta):\n",
    "    return y_i - predict(x_i, beta)\n",
    "\n",
    "def squared_error(x_i, y_i, beta):\n",
    "    return error(x_i, y_i, beta) ** 2\n",
    "\n",
    "def squared_error_gradient(x_i, y_i, beta):\n",
    "    \"\"\"the gradient corresponding to the ith squared error term\"\"\"\n",
    "    return [-2 * x_ij * error(x_i, y_i, beta)\n",
    "            for x_ij in x_i]\n",
    "\n",
    "def estimate_beta(x, y):\n",
    "    beta_initial = [random.random() for x_i in x[0]]\n",
    "    return minimize_stochastic(squared_error,\n",
    "                               squared_error_gradient,\n",
    "                               x, y,\n",
    "                               beta_initial,\n",
    "                               0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta [30.619881701311712, 0.9702056472470465, -1.8671913880379478, 0.9163711597955347]\n"
     ]
    }
   ],
   "source": [
    "x = [[1,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\n",
    "daily_minutes_good = [68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84]\n",
    "\n",
    "random.seed(0)\n",
    "beta = estimate_beta(x, daily_minutes_good) # [30.63, 0.972, -1.868, 0.911]\n",
    "print(\"beta\", beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness of Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared 0.6800074955952597\n"
     ]
    }
   ],
   "source": [
    "def multiple_r_squared(x, y, beta):\n",
    "    sum_of_squared_errors = sum(error(x_i, y_i, beta) ** 2\n",
    "                                for x_i, y_i in zip(x, y))\n",
    "    return 1.0 - sum_of_squared_errors / total_sum_of_squares(y)\n",
    "\n",
    "print(\"r-squared\", multiple_r_squared(x, daily_minutes_good, beta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digression: The Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digression: the bootstrap\n",
      "bootstrap_statistic(close_to_100, median, 100):\n",
      "[100.02634537429101, 100.06586584030461, 100.06850285070729, 100.06586584030461, 100.08022923777746, 100.02634537429101, 100.0251392489555, 100.06586584030461, 100.0251392489555, 100.18315165595742, 100.06627711829937, 100.06586584030461, 100.06627711829937, 100.06627711829937, 100.08022923777746, 100.08022923777746, 99.97928565593025, 99.95763666335068, 100.06627711829937, 99.95763666335068, 100.06586584030461, 100.06627711829937, 100.06850285070729, 100.08732646013036, 100.0340458696825, 100.02634537429101, 100.16675086620182, 100.11133261277095, 100.02634537429101, 100.0340458696825, 100.02048509159759, 100.06586584030461, 100.0340458696825, 100.02048509159759, 100.06850285070729, 100.06850285070729, 99.95763666335068, 100.08022923777746, 100.02048509159759, 100.07674830805912, 100.06586584030461, 100.06850285070729, 100.06627711829937, 100.11133261277095, 100.08022923777746, 100.06627711829937, 100.02634537429101, 100.0251392489555, 100.06850285070729, 100.06627711829937, 100.06586584030461, 100.0251392489555, 100.08022923777746, 100.11133261277095, 100.06586584030461, 100.0251392489555, 100.02634537429101, 100.04153611616675, 100.08022923777746, 100.06627711829937, 100.19440587880706, 100.04153611616675, 99.98693719710383, 100.06850285070729, 100.07674830805912, 100.08022923777746, 100.08732646013036, 100.06627711829937, 100.04153611616675, 100.08732646013036, 100.11133261277095, 100.06586584030461, 100.0251392489555, 100.13015471695907, 100.02634537429101, 99.95728292174014, 100.08732646013036, 100.06850285070729, 99.92424918869057, 100.02048509159759, 99.97928565593025, 99.92424918869057, 100.13015471695907, 100.06586584030461, 100.08022923777746, 100.06850285070729, 100.04153611616675, 100.06627711829937, 100.06586584030461, 100.06850285070729, 100.02048509159759, 100.02634537429101, 100.06627711829937, 100.04153611616675, 100.02634537429101, 100.02634537429101, 100.06627711829937, 100.18315165595742, 100.06850285070729, 100.06627711829937]\n",
      "bootstrap_statistic(far_from_100, median, 100):\n",
      "[0.9746929609488131, 0.9746929609488131, 0.9632764195933914, 200.0254523027627, 200.03723940374888, 0.9740127081653535, 200.0254523027627, 200.03723940374888, 0.9740127081653535, 200.043346407288, 200.06556682467556, 0.9679946120377706, 0.9229610720300252, 0.9170498145371947, 0.9746929609488131, 200.02972914757345, 100.37472916630605, 200.0439362129153, 0.9170498145371947, 0.9746929609488131, 0.9819299666825538, 0.9740127081653535, 200.02972914757345, 0.9819299666825538, 200.0439362129153, 200.03611456820246, 200.0439362129153, 200.02972914757345, 200.03611456820246, 200.0254523027627, 200.03723940374888, 0.9819299666825538, 0.9229610720300252, 0.9413891648644847, 0.9413891648644847, 200.01173496311017, 0.9746929609488131, 200.02972914757345, 200.043346407288, 0.9679946120377706, 200.07626904987512, 200.01173496311017, 0.9819299666825538, 200.01173496311017, 0.9632764195933914, 0.9746929609488131, 0.9746929609488131, 200.01173496311017, 0.9632764195933914, 0.9746929609488131, 200.02972914757345, 0.8082392572934448, 0.9413891648644847, 200.11842771777464, 0.9229610720300252, 0.9229610720300252, 100.37472916630605, 0.9819299666825538, 0.9740127081653535, 200.01173496311017, 200.03611456820246, 0.9819299666825538, 200.01173496311017, 0.9632764195933914, 200.0254523027627, 200.02972914757345, 200.02972914757345, 200.03611456820246, 0.9413891648644847, 100.37472916630605, 0.9170498145371947, 200.03723940374888, 0.9632764195933914, 0.8082392572934448, 0.9170498145371947, 200.01173496311017, 0.9746929609488131, 0.9746929609488131, 200.0439362129153, 100.37472916630605, 200.01173496311017, 200.03611456820246, 200.0254523027627, 0.9632764195933914, 200.02972914757345, 0.9740127081653535, 200.0254523027627, 100.37472916630605, 200.07626904987512, 0.9679946120377706, 200.02972914757345, 200.03723940374888, 200.01173496311017, 200.07626904987512, 0.9746929609488131, 0.9740127081653535, 0.9819299666825538, 200.01173496311017, 100.37472916630605, 100.37472916630605]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def bootstrap_sample(data):\n",
    "    \"\"\"randomly samples len(data) elements with replacement\"\"\"\n",
    "    return [random.choice(data) for _ in data]\n",
    "\n",
    "def bootstrap_statistic(data, stats_fn, num_samples):\n",
    "    \"\"\"evaluates stats_fn on num_samples bootstrap samples from data\"\"\"\n",
    "    return [stats_fn(bootstrap_sample(data))\n",
    "            for _ in range(num_samples)]\n",
    "\n",
    "print(\"digression: the bootstrap\")\n",
    "# 101 points all very close to 100\n",
    "close_to_100 = [99.5 + random.random() for _ in range(101)]\n",
    "\n",
    "# 101 points, 50 of them near 0, 50 of them near 200\n",
    "far_from_100 = ([99.5 + random.random()] +\n",
    "                [random.random() for _ in range(50)] +\n",
    "                [200 + random.random() for _ in range(50)])\n",
    "\n",
    "print(\"bootstrap_statistic(close_to_100, median, 100):\")\n",
    "print(bootstrap_statistic(close_to_100, median, 100))\n",
    "print(\"bootstrap_statistic(far_from_100, median, 100):\")\n",
    "print(bootstrap_statistic(far_from_100, median, 100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Errors of Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap standard errors [0.953551702104508, 0.06288763616183773, 0.11722269488203318, 0.8591786495949066]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def estimate_sample_beta(sample):\n",
    "    x_sample, y_sample = list(zip(*sample)) # magic unzipping trick\n",
    "    return estimate_beta(x_sample, y_sample)\n",
    "\n",
    "random.seed(0) # so that you get the same results as me\n",
    "\n",
    "bootstrap_betas = bootstrap_statistic(list(zip(x, daily_minutes_good)),\n",
    "                                      estimate_sample_beta,\n",
    "                                      100)\n",
    "\n",
    "bootstrap_standard_errors = [\n",
    "    standard_deviation([beta[i] for beta in bootstrap_betas])\n",
    "    for i in range(4)]\n",
    "\n",
    "print(\"bootstrap standard errors\", bootstrap_standard_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value(30.63, 1.174) 0.0\n",
      "p_value(0.972, 0.079) 0.0\n",
      "p_value(-1.868, 0.131) 0.0\n",
      "p_value(0.911, 0.990) 0.35746719881669264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def p_value(beta_hat_j, sigma_hat_j):\n",
    "    if beta_hat_j > 0:\n",
    "        return 2 * (1 - normal_cdf(beta_hat_j / sigma_hat_j))\n",
    "    else:\n",
    "        return 2 * normal_cdf(beta_hat_j / sigma_hat_j)\n",
    "    \n",
    "print(\"p_value(30.63, 1.174)\", p_value(30.63, 1.174))\n",
    "print(\"p_value(0.972, 0.079)\", p_value(0.972, 0.079))\n",
    "print(\"p_value(-1.868, 0.131)\", p_value(-1.868, 0.131))\n",
    "print(\"p_value(0.911, 0.990)\", p_value(0.911, 0.990))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization\n",
      "alpha 0.0\n",
      "beta [30.619881701311712, 0.9702056472470465, -1.8671913880379478, 0.9163711597955347]\n",
      "dot(beta[1:],beta[1:]) 5.267438780018153\n",
      "r-squared 0.6800074955952597\n",
      "\n",
      "alpha 0.01\n",
      "beta [30.55985204967343, 0.9730655363505671, -1.8624424625144256, 0.9317665551046306]\n",
      "dot(beta[1:],beta[1:]) 5.2837373774215655\n",
      "r-squared 0.680010213297079\n",
      "\n",
      "alpha 0.1\n",
      "beta [30.894860179735474, 0.9490275238632391, -1.8501720889216575, 0.5325129720515789]\n",
      "dot(beta[1:],beta[1:]) 4.607360065077926\n",
      "r-squared 0.6797276241305292\n",
      "\n",
      "alpha 1\n",
      "beta [30.666778908554885, 0.908635996761392, -1.6938673046100265, 0.09370161190283018]\n",
      "dot(beta[1:],beta[1:]) 3.7035858123105934\n",
      "r-squared 0.6757061537631815\n",
      "\n",
      "alpha 10\n",
      "beta [28.372861060795607, 0.7307660860322116, -0.9212163182015426, -0.018495551723207087]\n",
      "dot(beta[1:],beta[1:]) 1.3830006628491893\n",
      "r-squared 0.5752138470466858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# REGULARIZED REGRESSION\n",
    "#\n",
    "\n",
    "# alpha is a *hyperparameter* controlling how harsh the penalty is\n",
    "# sometimes it's called \"lambda\" but that already means something in Python\n",
    "def ridge_penalty(beta, alpha):\n",
    "  return alpha * dot(beta[1:], beta[1:])\n",
    "\n",
    "def squared_error_ridge(x_i, y_i, beta, alpha):\n",
    "    \"\"\"estimate error plus ridge penalty on beta\"\"\"\n",
    "    return error(x_i, y_i, beta) ** 2 + ridge_penalty(beta, alpha)\n",
    "\n",
    "def ridge_penalty_gradient(beta, alpha):\n",
    "    \"\"\"gradient of just the ridge penalty\"\"\"\n",
    "    return [0] + [2 * alpha * beta_j for beta_j in beta[1:]]\n",
    "\n",
    "def squared_error_ridge_gradient(x_i, y_i, beta, alpha):\n",
    "    \"\"\"the gradient corresponding to the ith squared error term\n",
    "    including the ridge penalty\"\"\"\n",
    "    return vector_add(squared_error_gradient(x_i, y_i, beta),\n",
    "                      ridge_penalty_gradient(beta, alpha))\n",
    "\n",
    "def estimate_beta_ridge(x, y, alpha):\n",
    "    \"\"\"use gradient descent to fit a ridge regression\n",
    "    with penalty alpha\"\"\"\n",
    "    beta_initial = [random.random() for x_i in x[0]]\n",
    "    return minimize_stochastic(partial(squared_error_ridge, alpha=alpha),\n",
    "                               partial(squared_error_ridge_gradient,\n",
    "                                       alpha=alpha),\n",
    "                               x, y,\n",
    "                               beta_initial,\n",
    "                               0.001)\n",
    "\n",
    "\n",
    "print(\"regularization\")\n",
    "\n",
    "random.seed(0)\n",
    "for alpha in [0.0, 0.01, 0.1, 1, 10]:\n",
    "    beta = estimate_beta_ridge(x, daily_minutes_good, alpha=alpha)\n",
    "    print(\"alpha\", alpha)\n",
    "    print(\"beta\", beta)\n",
    "    print(\"dot(beta[1:],beta[1:])\", dot(beta[1:], beta[1:]))\n",
    "    print(\"r-squared\", multiple_r_squared(x, daily_minutes_good, beta))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso_penalty\n",
      "alpha 0.0\n",
      "beta [30.619881701311712, 0.9702056472470465, -1.8671913880379478, 0.9163711597955347]\n",
      "dot(beta[1:],beta[1:]) 5.267438780018153\n",
      "r-squared 0.6800074955952597\n",
      "\n",
      "alpha 0.01\n",
      "beta [30.560550262459664, 0.9730242384213155, -1.862470999638158, 0.931232277088259]\n",
      "dot(beta[1:],beta[1:]) 5.282767946939525\n",
      "r-squared 0.6800102434732932\n",
      "\n",
      "alpha 0.1\n",
      "beta [30.885185176272103, 0.9481321522496409, -1.8501498420021165, 0.5361898836433593]\n",
      "dot(beta[1:],beta[1:]) 4.609508607311472\n",
      "r-squared 0.6797320305426815\n",
      "\n",
      "alpha 1\n",
      "beta [30.688605394437747, 0.9119173915552672, -1.7104776475328103, 0.062215174324354035]\n",
      "dot(beta[1:],beta[1:]) 3.7611978396465484\n",
      "r-squared 0.6762201927420475\n",
      "\n",
      "alpha 10\n",
      "beta [28.16883048374445, 0.7955796767330835, -0.9523734973203933, -0.010707778467903535]\n",
      "dot(beta[1:],beta[1:]) 1.5400769569487125\n",
      "r-squared 0.5888060531557244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def lasso_penalty(beta, alpha):\n",
    "    return alpha * sum(abs(beta_i) for beta_i in beta[1:])\n",
    "\n",
    "\n",
    "def squared_error_lasso(x_i, y_i, beta, alpha):\n",
    "    \"\"\"estimate error plus ridge penalty on beta\"\"\"\n",
    "    return error(x_i, y_i, beta) ** 2 + lasso_penalty(beta, alpha)\n",
    "\n",
    "def lasso_penalty_gradient(beta, alpha):\n",
    "    \"\"\"gradient of just the ridge penalty\"\"\"\n",
    "    return [0] + [2 * alpha * beta_j for beta_j in beta[1:]]\n",
    "\n",
    "def squared_error_lasso_gradient(x_i, y_i, beta, alpha):\n",
    "    \"\"\"the gradient corresponding to the ith squared error term\n",
    "    including the ridge penalty\"\"\"\n",
    "    return vector_add(squared_error_gradient(x_i, y_i, beta),\n",
    "                      lasso_penalty_gradient(beta, alpha))\n",
    "\n",
    "def estimate_beta_lasso(x, y, alpha):\n",
    "    \"\"\"use gradient descent to fit a ridge regression\n",
    "    with penalty alpha\"\"\"\n",
    "    beta_initial = [random.random() for x_i in x[0]]\n",
    "    return minimize_stochastic(partial(squared_error_lasso, alpha=alpha),\n",
    "                               partial(squared_error_lasso_gradient,\n",
    "                                       alpha=alpha),\n",
    "                               x, y,\n",
    "                               beta_initial,\n",
    "                               0.001)\n",
    "\n",
    "print(\"lasso_penalty\")\n",
    "\n",
    "random.seed(0)\n",
    "for alpha in [0.0, 0.01, 0.1, 1, 10]:\n",
    "    beta = estimate_beta_lasso(x, daily_minutes_good, alpha=alpha)\n",
    "    print(\"alpha\", alpha)\n",
    "    print(\"beta\", beta)\n",
    "    print(\"dot(beta[1:],beta[1:])\", dot(beta[1:], beta[1:]))\n",
    "    print(\"r-squared\", multiple_r_squared(x, daily_minutes_good, beta))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the scikit-learn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge (alpha = .5)\n",
    "reg.fit(x, daily_minutes_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.97170741, -1.86459997,  0.90823708])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.590236115326242"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
